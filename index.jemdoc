# jemdoc: showsource
= Brendan O'Donoghue

~~~
{}{img_left}{profile.jpeg}{Brendan O'Donoghue}{600}{360}
Brendan O'Donoghue, Ph.D. \n
Research Scientist at [http://deepmind.com/ DeepMind] \n
Former advisor: [http://www.stanford.edu/~boyd/ Professor Stephen Boyd] \n
[https://scholar.google.com/citations?user=0Pzjj-cAAAAJ Google scholar profile] \n
\n
Contact: [bodonoghue85@gmail.com email], [https://twitter.com/bodonoghue85 twitter], [https://github.com/bodono github]

~~~

== Education
- Ph.D., M.S., [http://ee.stanford.edu Electrical Engineering], [http://www.stanford.edu Stanford University],
  January 2013 \n
- B.A., M.A., M.Eng., Information and Computer Engineering,
  [http://www.cai.cam.ac.uk/ Gonville and Caius College],
  [http://www.cam.ac.uk/ Cambridge University], June 2007

== Interests and current research
- Convex optimization
- Machine Learning
- Reinforcement Learning
- Dynamic systems and control

== Software
- [https://github.com/cvxgrp/scs SCS]: C package for solving convex cone problems via operator splitting

== Publications
:{[https://arxiv.org/pdf/2106.00661.pdf Reward is enough for convex MDPs]} T. Zahavy, B. O'Donoghue, G. Desjardins, and S. Singh
:{[https://arxiv.org/pdf/2106.00669.pdf Discovering diverse nearly optimal policies with successor features]} T. Zahavy, B. O'Donoghue, A. Barreto, V. Mnih, S. Flennerhag, and S. Singh
:{[https://openreview.net/forum?id=PUkhWz65dy5 Discovering a set of policies for the worst case reward]} T. Zahavy, A. Barreto, D. Mankowitz, S. Hou, B. O'Donoghue, I. Kemaev, and S. Singh
:{[https://arxiv.org/abs/2012.13349 Solving Mixed Integer Programs Using Neural Networks]} V. Nair, S. Bartunov, F. Gimeno, I. von Glehn, P. Lichocki, I. Lobov, B. O'Donoghue, N. Sonnerat, C. Tjandraatmadja, P. Wang /et al./
:{[https://web.stanford.edu/~boyd/papers/conv_reinforce.html Sample Efficient Reinforcement Learning with REINFORCE]} J. Zhang, J. Kim, B. O'Donoghue, and S. Boyd
:{[https://arxiv.org/abs/2006.05145 Stochastic matrix games with bandit feedback]} B. O'Donoghue, T. Lattimore, and I. Osband
:{[https://arxiv.org/abs/2004.02177 Operator splitting for a homogeneous embedding of the monotone linear complementarity problem]} B. O'Donoghue
:{[https://arxiv.org/abs/2001.00805 Making sense of reinforcement learning and probabilistic inference]} B. O'Donoghue, I Osband, and C. Ionescu
:{[https://arxiv.org/abs/1906.02608 Hamiltonian descent for composite objectives]} B. O'Donoghue and C. J. Maddison
:{[https://debug-ml-iclr2019.github.io/cameraready/DebugML-19_paper_6.pdf Visualizations of decision regions in the presence of adversarial examples]} G. Swirszcz, B. O'Donoghue, and P. Kohli
:{[https://openreview.net/pdf?id=HyeFAsRctQ Verification of non-linear specifications for neural networks]} C. Qin, K. (Dj) Dvijotham, B. O’Donoghue, R. Bunel, R. Stanforth, S. Gowal, J. Uesato, G. Swirszcz, and P. Kohli
:{[https://arxiv.org/abs/1811.09300 Strength in numbers: Trading-off robustness and computation via adversarially-trained ensembles]} E. Grefenstette, R. Stanforth, B. O'Donoghue, J. Uesato, G. Swirszcz, and P. Kohli
:{[https://arxiv.org/abs/1809.05042 Hamiltonian descent methods]} C. J. Maddison, D. Paulin, Y. W. Teh, B. O'Donoghue, and A. Doucet
:{[https://rdcu.be/4sNU Clinically applicable deep learning for diagnosis and referral in retinal disease]} J. De Fauw /et al./
:{[http://www.stanford.edu/~boyd/papers/nonexp_global_aa1.html Globally convergent type-I Anderson acceleration for non-smooth fixed-point iterations]} J. Zhang, B. O'Donoghue, and S. Boyd
:{[https://arxiv.org/abs/1807.09647 Variational Bayesian reinforcement learning with regret bounds]} B. O'Donoghue
:{[https://arxiv.org/abs/1805.10265 Training verified learners with learned verifiers]} K. (Dj) Dvijotham, S. Gowal, R. Stanforth, R. Arandjelovic, B. O'Donoghue, J. Uesato, and P. Kohli
:{[https://arxiv.org/abs/1802.05666 Adversarial risk and the dangers of evaluating against weak attacks]} J. Uesato, B. O'Donoghue, A. van den Oord, and P. Kohli
:{[https://arxiv.org/abs/1709.05380 The uncertainty Bellman equation and exploration]} B. O'Donoghue, I. Osband, R. Munos, and V. Mnih
:{[https://arxiv.org/abs/1611.01626 Combining policy gradient and Q-learning]} B. O'Donoghue, R. Munos, K. Kavukcuoglu, and V. Mnih
:{[publications/wireless.pdf Large-scale convex optimization for dense wireless cooperative networks]} Y. Shi, J. Zhang, B. O’Donoghue, and K. Letaief
:{[http://www.stanford.edu/~boyd/papers/scs.html Conic optimization via operator splitting and homogeneous self-dual embedding]} B. O'Donoghue, E. Chu, N. Parikh, and S. Boyd
:{[http://www.stanford.edu/~boyd/papers/pdos.html A primal-dual operator splitting method for conic optimization]} E. Chu, B. O'Donoghue, N. Parikh, and S. Boyd
:{[http://www.stanford.edu/~boyd/papers/adp_iter_bellman.html Approximate dynamic programming via iterated Bellman Inequalities]} Y. Wang, B. O'Donoghue, and S. Boyd
:{[http://www.stanford.edu/~boyd/papers/it_avf.html Iterated approximate value functions]} B. O'Donoghue, Y. Wang, and S. Boyd
:{[http://www.stanford.edu/~boyd/papers/oper_splt_ctrl.html A splitting method for optimal control]} B. O'Donoghue, G. Stathopoulos, and S. Boyd
:{[ftp://ftp.math.ucla.edu/pub/camreport/cam12-35.pdf Fast alternating direction optimization methods]} T. Goldstein, B. O'Donoghue, and S. Setzer
:{[http://www.stanford.edu/~boyd/papers/port_opt_bound.html Performance bounds and suboptimal policies for multi-period investment]} S. Boyd, M. Mueller, B. O'Donoghue, and Y. Wang
:{[publications/adap_restart.pdf Adaptive restart for accelerated gradient schemes]} B. O'Donoghue and E. J. Candès
:{[publications/oplc.pdf A spread-return mean-reverting model for credit spread dynamics]} B. O'Donoghue, M. Peacock, J. Lee, and L. Capriotti
:{[http://www.stanford.edu/~boyd/papers/min_max_adp.html Min-max approximate dynamic programming]} B. O'Donoghue, Y. Wang, and S. Boyd

== Ph.D. Thesis
:{[thesis/bod_thesis.pdf Suboptimal Control Policies via Convex Optimization]} B. O'Donoghue
