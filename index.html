<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />
<title>Brendan O'Donoghue</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Brendan O'Donoghue</h1>
</div>
<table class="imgtable"><tr><td>
<img src="profile.jpeg" alt="Brendan O'Donoghue" width="600px" height="310px" />&nbsp;</td>
<td align="left"><p>Brendan O'Donoghue, Ph.D. <br />
Research Scientist at <a href="http://deepmind.com/">DeepMind</a> <br />
Former advisor: <a href="http://www.stanford.edu/~boyd/">Professor Stephen Boyd</a> <br />
<a href="https://scholar.google.com/citations?user=0Pzjj-cAAAAJ">Google scholar profile</a> <br />
<br />
Contact: <a href="mailto:bodonoghue85@gmail.com">email</a>, <a href="https://twitter.com/bodonoghue85">twitter</a>, <a href="https://github.com/bodono">github</a></p>
</td></tr></table>
<h2>Education</h2>
<ul>
<li><p>Ph.D., M.S., <a href="http://ee.stanford.edu">Electrical Engineering</a>, <a href="http://www.stanford.edu">Stanford University</a>,
January 2013 <br /></p>
</li>
<li><p>B.A., M.A., M.Eng., Information and Computer Engineering,
<a href="http://www.cai.cam.ac.uk/">Gonville and Caius College</a>,
<a href="http://www.cam.ac.uk/">Cambridge University</a>, June 2007</p>
</li>
</ul>
<h2>Interests and current research</h2>
<ul>
<li><p>Convex optimization</p>
</li>
<li><p>Machine Learning</p>
</li>
<li><p>Reinforcement Learning</p>
</li>
<li><p>Dynamic systems and control</p>
</li>
</ul>
<h2>Software</h2>
<ul>
<li><p><a href="https://github.com/cvxgrp/scs">SCS</a>: C package for solving convex cone problems via operator splitting</p>
</li>
</ul>
<h2>Publications</h2>
<dl>
<dt><a href="https://openreview.net/forum?id=PUkhWz65dy5">Discovering a set of policies for
the worst case reward</a></dt>
<dd><p>T. Zahavy, A. Barreto, D. Mankowitz, S. Hou, B. O'Donoghue, I. Kemaev, and S. Singh</p></dd>
<dt><a href="https://arxiv.org/abs/2012.13349">Solving Mixed Integer Programs Using Neural Networks</a></dt>
<dd><p>V. Nair, S. Bartunov, F. Gimeno, I. von Glehn, P. Lichocki, I. Lobov, B. O'Donoghue, N. Sonnerat, C. Tjandraatmadja, P. Wang <i>et al.</i></p></dd>
<dt><a href="https://web.stanford.edu/~boyd/papers/conv_reinforce.html">Sample Efficient Reinforcement Learning with REINFORCE</a></dt>
<dd><p>J. Zhang, J. Kim, B. O'Donoghue, and S. Boyd</p></dd>
<dt><a href="https://arxiv.org/abs/2006.05145">Stochastic matrix games with bandit feedback</a></dt>
<dd><p>B. O'Donoghue, T. Lattimore, and I. Osband</p></dd>
<dt><a href="https://arxiv.org/abs/2004.02177">Operator splitting for a homogeneous embedding of the monotone linear complementarity problem</a></dt>
<dd><p>B. O'Donoghue</p></dd>
<dt><a href="https://arxiv.org/abs/2001.00805">Making sense of reinforcement learning and probabilistic inference</a></dt>
<dd><p>B. O'Donoghue, I Osband, and C. Ionescu</p></dd>
<dt><a href="https://arxiv.org/abs/1906.02608">Hamiltonian descent for composite objectives</a></dt>
<dd><p>B. O'Donoghue and C. J. Maddison</p></dd>
<dt><a href="https://debug-ml-iclr2019.github.io/cameraready/DebugML-19_paper_6.pdf">Visualizations of decision regions in the presence of adversarial examples</a></dt>
<dd><p>G. Swirszcz, B. O'Donoghue, and P. Kohli</p></dd>
<dt><a href="https://openreview.net/pdf?id=HyeFAsRctQ">Verification of non-linear specifications for neural networks</a></dt>
<dd><p>C. Qin, K. (Dj) Dvijotham, B. O’Donoghue, R. Bunel, R. Stanforth, S. Gowal, J. Uesato, G. Swirszcz, and P. Kohli</p></dd>
<dt><a href="https://arxiv.org/abs/1811.09300">Strength in numbers: Trading-off robustness and computation via adversarially-trained ensembles</a></dt>
<dd><p>E. Grefenstette, R. Stanforth, B. O'Donoghue, J. Uesato, G. Swirszcz, and P. Kohli</p></dd>
<dt><a href="https://arxiv.org/abs/1809.05042">Hamiltonian descent methods</a></dt>
<dd><p>C. J. Maddison, D. Paulin, Y. W. Teh, B. O'Donoghue, and A. Doucet</p></dd>
<dt><a href="https://rdcu.be/4sNU">Clinically applicable deep learning for diagnosis and referral in retinal disease</a></dt>
<dd><p>J. De Fauw <i>et al.</i></p></dd>
<dt><a href="http://www.stanford.edu/~boyd/papers/nonexp_global_aa1.html">Globally convergent type-I Anderson acceleration for non-smooth fixed-point iterations</a></dt>
<dd><p>J. Zhang, B. O'Donoghue, and S. Boyd</p></dd>
<dt><a href="https://arxiv.org/abs/1807.09647">Variational Bayesian reinforcement learning with regret bounds</a></dt>
<dd><p>B. O'Donoghue</p></dd>
<dt><a href="https://arxiv.org/abs/1805.10265">Training verified learners with learned verifiers</a></dt>
<dd><p>K. (Dj) Dvijotham, S. Gowal, R. Stanforth, R. Arandjelovic, B. O'Donoghue, J. Uesato, and P. Kohli</p></dd>
<dt><a href="https://arxiv.org/abs/1802.05666">Adversarial risk and the dangers of evaluating against weak attacks</a></dt>
<dd><p>J. Uesato, B. O'Donoghue, A. van den Oord, and P. Kohli</p></dd>
<dt><a href="https://arxiv.org/abs/1709.05380">The uncertainty Bellman equation and exploration</a></dt>
<dd><p>B. O'Donoghue, I. Osband, R. Munos, and V. Mnih</p></dd>
<dt><a href="https://arxiv.org/abs/1611.01626">Combining policy gradient and Q-learning</a></dt>
<dd><p>B. O'Donoghue, R. Munos, K. Kavukcuoglu, and V. Mnih</p></dd>
<dt><a href="publications/wireless.pdf">Large-scale convex optimization for dense wireless cooperative networks</a></dt>
<dd><p>Y. Shi, J. Zhang, B. O’Donoghue, and K. Letaief</p></dd>
<dt><a href="http://www.stanford.edu/~boyd/papers/scs.html">Conic optimization via operator splitting and homogeneous self-dual embedding</a></dt>
<dd><p>B. O'Donoghue, E. Chu, N. Parikh, and S. Boyd</p></dd>
<dt><a href="http://www.stanford.edu/~boyd/papers/pdos.html">A primal-dual operator splitting method for conic optimization</a></dt>
<dd><p>E. Chu, B. O'Donoghue, N. Parikh, and S. Boyd</p></dd>
<dt><a href="http://www.stanford.edu/~boyd/papers/adp_iter_bellman.html">Approximate dynamic programming via iterated Bellman Inequalities</a></dt>
<dd><p>Y. Wang, B. O'Donoghue, and S. Boyd</p></dd>
<dt><a href="http://www.stanford.edu/~boyd/papers/it_avf.html">Iterated approximate value functions</a></dt>
<dd><p>B. O'Donoghue, Y. Wang, and S. Boyd</p></dd>
<dt><a href="http://www.stanford.edu/~boyd/papers/oper_splt_ctrl.html">A splitting method for optimal control</a></dt>
<dd><p>B. O'Donoghue, G. Stathopoulos, and S. Boyd</p></dd>
<dt><a href="ftp://ftp.math.ucla.edu/pub/camreport/cam12-35.pdf">Fast alternating direction optimization methods</a></dt>
<dd><p>T. Goldstein, B. O'Donoghue, and S. Setzer</p></dd>
<dt><a href="http://www.stanford.edu/~boyd/papers/port_opt_bound.html">Performance bounds and suboptimal policies for multi-period investment</a></dt>
<dd><p>S. Boyd, M. Mueller, B. O'Donoghue, and Y. Wang</p></dd>
<dt><a href="publications/adap_restart.pdf">Adaptive restart for accelerated gradient schemes</a></dt>
<dd><p>B. O'Donoghue and E. J. Candès</p></dd>
<dt><a href="publications/oplc.pdf">A spread-return mean-reverting model for credit spread dynamics</a></dt>
<dd><p>B. O'Donoghue, M. Peacock, J. Lee, and L. Capriotti</p></dd>
<dt><a href="http://www.stanford.edu/~boyd/papers/min_max_adp.html">Min-max approximate dynamic programming</a></dt>
<dd><p>B. O'Donoghue, Y. Wang, and S. Boyd</p></dd>
</dl>
<h2>Ph.D. Thesis</h2>
<dl>
<dt><a href="thesis/bod_thesis.pdf">Suboptimal Control Policies via Convex Optimization</a></dt>
<dd><p>B. O'Donoghue</p></dd>
</dl>
<div id="footer">
<div id="footer-text">
Page generated 2021-04-06 18:01:12 BST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
(<a href="index.jemdoc">source</a>)
</div>
</div>
</div>
</body>
</html>
