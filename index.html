<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="css/jemdoc.css" type="text/css" />
<title>Brendan O'Donoghue</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Brendan O'Donoghue</h1>
</div>
<table class="imgtable"><tr><td>
<img src="profile.jpeg" alt="Brendan O'Donoghue" width="350px" height="350px" />&nbsp;</td>
<td align="left"><p>Brendan O'Donoghue, Ph.D. <br />
Research Scientist at <a href="http://deepmind.com/">DeepMind</a> <br />
Former advisor: <a href="http://www.stanford.edu/~boyd/">Professor Stephen Boyd</a> <br />
<a href="https://scholar.google.com/citations?user=0Pzjj-cAAAAJ">Google scholar profile</a> <br />
<br />
Contact: <a href="mailto:bodonoghue85@gmail.com">email</a>, <a href="https://twitter.com/bodonoghue85">twitter</a>, <a href="https://github.com/bodono">github</a></p>
</td></tr></table>
<h2>Education</h2>
<ul>
<li><p>Ph.D., M.S., Computer Science, <br />
<a href="http://www.stanford.edu">Stanford University</a>,
January 2013 <br /></p>
</li>
<li><p>B.A., M.A., M.Eng., Information and Computer Engineering, <br />
<a href="http://www.cai.cam.ac.uk/">Gonville and Caius College</a>, <br />
<a href="http://www.cam.ac.uk/">Cambridge University</a>, June 2007</p>
</li>
</ul>
<h2>Interests and current research</h2>
<ul>
<li><p>Artificial intelligence</p>
</li>
<li><p>Machine learning</p>
</li>
<li><p>Reinforcement learning</p>
</li>
<li><p>Dynamic systems and control</p>
</li>
<li><p>Convex optimization</p>
</li>
</ul>
<h2>Software</h2>
<ul>
<li><p><a href="https://www.cvxgrp.org/scs/">SCS</a>: Large-scale convex quadratic cone solver.</p>
</li>
</ul>
<h2>Journal Articles</h2>
<dl>
<dt><a href="https://arxiv.org/abs/2212.14530">POMRL: No-regret learning-to-plan with increasing horizons</a></dt>
<dd><p>K. Khetarpal, C. Vernade, B. O'Donoghue, S. Singh, and T. Zahavy <br />
<i>Transactions on Machine Learning Research (TMLR)</i>, 2023.</p></dd>
</dl>
<dl>
<dt><a href="publications/quad_scs.pdf">Operator splitting for a homogeneous embedding of the monotone linear complementarity problem</a></dt>
<dd><p>B. O'Donoghue <br />
<i>SIAM Journal on Optimization</i>, 31(3), pp. 1999-2023, August 2021.</p></dd>
</dl>
<dl>
<dt><a href="http://www.stanford.edu/~boyd/papers/nonexp_global_aa1.html">Globally convergent type-I Anderson acceleration for non-smooth fixed-point iterations</a></dt>
<dd><p>J. Zhang, B. O'Donoghue, and S. Boyd <br />
<i>SIAM Journal on Optimization</i>, 30(4), pp. 3170-3197, November 2020.</p></dd>
</dl>
<dl>
<dt><a href="https://rdcu.be/4sNU">Clinically applicable deep learning for diagnosis and referral in retinal disease</a></dt>
<dd><p>J. De Fauw, <i>et al.</i> <br />
<i>Nature Medicine</i>, 24(9), pp. 1342-1350, August 2018.</p></dd>
</dl>
<dl>
<dt><a href="http://www.stanford.edu/~boyd/papers/scs.html">Conic optimization via operator splitting and homogeneous self-dual embedding</a></dt>
<dd><p>B. O'Donoghue, E. Chu, N. Parikh, and S. Boyd <br />
<i>Journal of Optimization Theory and Applications</i>, 169(3), pp. 1042-1068, June 2016.</p></dd>
</dl>
<dl>
<dt><a href="publications/wireless.pdf">Large-scale convex optimization for dense wireless cooperative networks</a></dt>
<dd><p>Y. Shi, J. Zhang, B. O'Donoghue, and K. Letaief <br />
<i>IEEE Transactions on Signal Processing</i>, 63(18), pp. 4729-4743, September 2015.<br />
<b>IEEE 2016 SPS Young Author Best Paper Award</b>.</p></dd>
</dl>
<dl>
<dt><a href="http://www.stanford.edu/~boyd/papers/adp_iter_bellman.html">Approximate dynamic programming via iterated Bellman Inequalities</a></dt>
<dd><p>Y. Wang, B. O'Donoghue, and S. Boyd <br />
<i>International Journal of Robust and Nonlinear Control</i>, 25(10), pp. 1472-1496, July 2015.</p></dd>
</dl>
<dl>
<dt><a href="publications/adap_restart.pdf">Adaptive restart for accelerated gradient schemes</a></dt>
<dd><p>B. O'Donoghue and E. J. Candès <br />
<i>Foundations of computational mathematics</i>, 15(3), pp. 715-732, June 2015.</p></dd>
</dl>
<dl>
<dt><a href="https://scholarship.rice.edu/bitstream/handle/1911/94752/Optimization-Methods.pdf?sequence=4">Fast alternating direction optimization methods</a></dt>
<dd><p>T. Goldstein, B. O'Donoghue, S. Setzer, and R. Baraniuk <br />
<i>SIAM Journal on Imaging Sciences</i>, 7(3), pp.1588-1623, August 2014.</p></dd>
</dl>
<dl>
<dt><a href="publications/oplc.pdf">A spread-return mean-reverting model for credit spread dynamics</a></dt>
<dd><p>B. O'Donoghue, M. Peacock, J. Lee, and L. Capriotti <br />
<i>International Journal of Theoretical and Applied Finance</i>, 17(3), pp. 1-14, May 2014.</p></dd>
</dl>
<dl>
<dt><a href="http://www.stanford.edu/~boyd/papers/port_opt_bound.html">Performance bounds and suboptimal policies for multi-period investment</a></dt>
<dd><p>S. Boyd, M. Mueller, B. O'Donoghue, and Y. Wang <br />
<i>Foundations and Trends in Optimization</i>, 1(1), pp. 1-69, January 2014.</p></dd>
</dl>
<dl>
<dt><a href="http://www.stanford.edu/~boyd/papers/oper_splt_ctrl.html">A splitting method for optimal control</a></dt>
<dd><p>B. O'Donoghue, G. Stathopoulos, and S. Boyd <br />
<i>IEEE Transactions on Control Systems Technology</i>, 21(6), pp. 2432-2442, November 2013.</p></dd>
</dl>
<h2>Conference Articles</h2>
<dl>
<dt><a href="https://arxiv.org/abs/2311.13294">Probabilistic inference in reinforcement learning done right</a></dt>
<dd><p>J. Tarbouriech, T. Lattimore, and B. O'Donoghue <br />
<i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2023.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2301.03236">Optimistic meta-gradients</a></dt>
<dd><p>S. Flennerhag, T. Zahavy, B. O'Donoghue, H. van Hasselt, A. György, and S. Singh <br />
<i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2023.</p></dd>
</dl>
<dl>
<dt><a href="http://arxiv.org/abs/2302.09339">Efficient exploration via epistemic-risk-seeking policy optimization</a></dt>
<dd><p>B. O'Donoghue <br />
<i>Proceedings of the International Conference on Machine Learning (ICML)</i>, 2023.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2302.01275">ReLOAD: Reinforcement learning with optimistic ascent-descent for last-iterate convergence in constrained MDPs</a></dt>
<dd><p>T. Moskovitz, B. O'Donoghue, V. Veeriah, S. Flennerhag, S. Singh, and T. Zahavy <br />
<i>Proceedings of the International Conference on Machine Learning (ICML)</i>, 2023.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2110.04629">The neural testbed: Evaluating joint predictions</a></dt>
<dd><p>I. Osband, Z. Wen, S. Asghari, V. Dwaracherla, B. Hao, M. Ibrahimi, D. Lawson, X. Lu, B. O'Donoghue, and B. Van Roy <br />
<i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2022.</p></dd>
</dl>
<dl>
<dt><a href="http://arxiv.org/abs/2110.15688">Variational Bayesian optimistic sampling</a></dt>
<dd><p>B. O'Donoghue and T. Lattimore <br />
<b>Spotlight</b> <i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2021.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/pdf/2106.00661.pdf">Reward is enough for convex MDPs</a></dt>
<dd><p>T. Zahavy, B. O'Donoghue, G. Desjardins, and S. Singh <br />
<b>Spotlight</b> <i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2021.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/1807.09647">Variational Bayesian reinforcement learning with regret bounds</a></dt>
<dd><p>B. O'Donoghue <br />
<i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2021.</p></dd>
</dl>
<dl>
<dt><a href="http://www.optimization-online.org/DB_HTML/2021/06/8439.html">Practical large-scale linear programming using primal-dual hybrid gradient</a></dt>
<dd><p>D. Applegate, M. Díaz, O. Hinder, H. Lu, M. Lubin, B. O'Donoghue, and W. Schudy <br />
<i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2021.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2006.05145">Matrix games with bandit feedback</a></dt>
<dd><p>B. O'Donoghue, T. Lattimore, and I. Osband <br />
<i>Proceedings of the 37th Conference on Uncertainty in Artificial Intelligence</i>, (UAI), 2021.</p></dd>
</dl>
<dl>
<dt><a href="https://openreview.net/forum?id=PUkhWz65dy5">Discovering a set of policies for the worst case reward</a></dt>
<dd><p>T. Zahavy, A. Barreto, D. Mankowitz, S. Hou, B. O'Donoghue, I. Kemaev, and S. Singh <br />
<b>Spotlight</b> <i>Proceedings of the International Conference on Learning Representations (ICLR)</i>, 2021.</p></dd>
</dl>
<dl>
<dt><a href="https://web.stanford.edu/~boyd/papers/conv_reinforce.html">Sample Efficient Reinforcement Learning with REINFORCE</a></dt>
<dd><p>J. Zhang, J. Kim, B. O'Donoghue, and S. Boyd <br />
<i>Proceedings of the AAAI Conference on Artificial Intelligence</i>, 35(12), 10887-10895, 2021.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2001.00805">Making sense of reinforcement learning and probabilistic inference</a></dt>
<dd><p>B. O'Donoghue, I Osband, and C. Ionescu <br />
<b>Spotlight</b> <i>Proceedings of the International Conference on Learning Representations (ICLR)</i>, 2020.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/1906.02608">Hamiltonian descent for composite objectives</a></dt>
<dd><p>B. O'Donoghue and C. J. Maddison <br />
<i>Advances in Neural Information Processing Systems (NeurIPS)</i>, 2019.</p></dd>
</dl>
<dl>
<dt><a href="https://debug-ml-iclr2019.github.io/cameraready/DebugML-19_paper_6.pdf">Visualizations of decision regions in the presence of adversarial examples</a></dt>
<dd><p>G. Swirszcz, B. O'Donoghue, and P. Kohli <br />
<i>Debugging Machine Learning Models Workshop</i>, ICLR, 2019.</p></dd>
</dl>
<dl>
<dt><a href="https://openreview.net/pdf?id=HyeFAsRctQ">Verification of non-linear specifications for neural networks</a></dt>
<dd><p>C. Qin, K. (Dj) Dvijotham, B. O'Donoghue, R. Bunel, R. Stanforth, S. Gowal, J. Uesato, G. Swirszcz, and P. Kohli <br />
<i>Proceedings of the International Conference on Learning Representations (ICLR)</i>, 2019.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/1802.05666">Adversarial risk and the dangers of evaluating against weak attacks</a></dt>
<dd><p>J. Uesato, B. O'Donoghue, A. van den Oord, and P. Kohli <br />
<i>Proceedings of the International Conference on Machine Learning (ICML)</i>, pp. 5025-5034, 2018.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/1709.05380">The uncertainty Bellman equation and exploration</a></dt>
<dd><p>B. O'Donoghue, I. Osband, R. Munos, and V. Mnih <br />
<b>Oral</b> <i>Proceedings of the International Conference on Machine Learning (ICML)</i>, pp. 3836-3845. 2018.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/1611.01626">Combining policy gradient and Q-learning</a></dt>
<dd><p>B. O'Donoghue, R. Munos, K. Kavukcuoglu, and V. Mnih <br />
<i>Proceedings of the International Conference on Learning Representations (ICLR)</i>, 2017.</p></dd>
</dl>
<dl>
<dt><a href="http://www.stanford.edu/~boyd/papers/it_avf.html">Iterated approximate value functions</a></dt>
<dd><p>B. O'Donoghue, Y. Wang, and S. Boyd <br />
<i>Proceedings European Control Conference</i>, pp. 3882-3888, Zurich, July 2013.</p></dd>
</dl>
<dl>
<dt><a href="http://www.stanford.edu/~boyd/papers/min_max_adp.html">Min-max approximate dynamic programming</a></dt>
<dd><p>B. O'Donoghue, Y. Wang, and S. Boyd <br />
<i>Proceedings IEEE Multi-Conference on Systems and Control</i>, pp. 424-431, September 2011.</p></dd>
</dl>
<h2>Other</h2>
<dl>
<dt><a href="https://arxiv.org/abs/2210.12160">On the connection between Bregman divergence and value in regularized Markov decision processes</a></dt>
<dd><p>B. O'Donoghue <br />
Technical note, 2022.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/2012.13349">Solving mixed integer programs using neural networks</a></dt>
<dd><p>V. Nair*, S. Bartunov*, F. Gimeno*, I. von Glehn*, P. Lichocki*, I. Lobov*, B. O'Donoghue*, N. Sonnerat*, C. Tjandraatmadja*, P. Wang*, <i>et al.</i> <br />
(* Equal contribution). In submission, 2021.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/pdf/2106.00669.pdf">Discovering diverse nearly optimal policies with successor features</a></dt>
<dd><p>T. Zahavy, B. O'Donoghue, A. Barreto, V. Mnih, S. Flennerhag, and S. Singh <br />
Working draft, 2021.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/1811.09300">Strength in numbers: Trading-off robustness and computation via adversarially-trained ensembles</a></dt>
<dd><p>E. Grefenstette, R. Stanforth, B. O'Donoghue, J. Uesato, G. Swirszcz, and P. Kohli <br />
Working draft, 2018.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/1809.05042">Hamiltonian descent methods</a></dt>
<dd><p>C. J. Maddison, D. Paulin, Y. W. Teh, B. O'Donoghue, and A. Doucet <br />
Working draft, 2018.</p></dd>
</dl>
<dl>
<dt><a href="https://arxiv.org/abs/1805.10265">Training verified learners with learned verifiers</a></dt>
<dd><p>K. (Dj) Dvijotham, S. Gowal, R. Stanforth, R. Arandjelovic, B. O'Donoghue, J. Uesato, and P. Kohli <br />
Working draft, 2018.</p></dd>
</dl>
<dl>
<dt><a href="http://www.stanford.edu/~boyd/papers/pdos.html">A primal-dual operator splitting method for conic optimization</a></dt>
<dd><p>E. Chu, B. O'Donoghue, N. Parikh, and S. Boyd <br />
<i>Stanford internal report</i>, (2013).</p></dd>
</dl>
<h2>Ph.D. Thesis</h2>
<dl>
<dt><a href="thesis/bod_thesis.pdf">Suboptimal control policies via convex optimization</a></dt>
<dd><p>B. O'Donoghue</p></dd>
</dl>
<div id="footer">
<div id="footer-text">
Page generated 2023-11-23 10:55:16 GMT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
(<a href="index.jemdoc">source</a>)
</div>
</div>
</div>
</body>
</html>
